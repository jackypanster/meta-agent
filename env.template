# 环境变量配置模板
# 复制此文件为 .env 并填入真实的API密钥

# ====== LLM 模型配置 ======

# 模型名称选择 (必需)
# 可选值: 
#   deepseek-chat      - DeepSeek V3 稳定模型
#   deepseek-reasoner  - DeepSeek R1 推理模型
#   qwen3-32b         - 本地部署的Qwen3-32B模型
MODEL_NAME=deepseek-chat

# ====== DeepSeek 配置 (当使用 deepseek-* 模型时) ======
# DeepSeek API 密钥 (必需)
# 从 https://platform.deepseek.com/ 获取
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# ====== Qwen3-32B 配置 (当使用 qwen3-32b 模型时) ======
# 本地VLLM部署的API密钥，通常设置为"EMPTY"
QWEN3_API_KEY=EMPTY
# 本地VLLM服务器地址
QWEN3_MODEL_SERVER=http://localhost:8000/v1
# 是否启用思考模式 (可选，默认false)
# 设置为true启用思考模式，false禁用思考模式
QWEN3_ENABLE_THINKING=false

# ====== 其他配置 ======

# OpenRouter API 密钥 (可选，作为备用)
# 从 https://openrouter.ai/ 获取
OPENROUTER_API_KEY=your_openrouter_api_key_here

# MCP 服务器URL (可选)
# 默认使用 Context7 的服务器
MCP_SERVER_URL=https://mcp.context7.com/sse 