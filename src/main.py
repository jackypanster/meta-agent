#!/usr/bin/env python3
"""
Qwen-Agent MVP - ÁÆÄÊ¥ÅÁõ¥ËßÇÂÆûÁé∞

Âü∫‰∫éÂÆòÊñπQwen-AgentÊ°ÜÊû∂ÁöÑÊúÄÁÆÄÊ¥ÅÂÆûÁé∞Ôºö
- Áõ¥Êé•‰ΩøÁî®AssistantÁ±ª
- Ê®°ÂùóÂåñÂ∑•ÂÖ∑Á≥ªÁªü
- ÁÆÄÂçïÁöÑÂÜÖÂ≠òÁÆ°ÁêÜ
- Áõ¥ËßÇÁöÑCLIÁïåÈù¢
- ‰ΩøÁî®ÊúÄÊñ∞DeepSeek-R1-0528Êé®ÁêÜÊ®°Âûã
"""

import time
import requests
from typing import Dict, List, Any

# Qwen-Agent imports
from qwen_agent.agents import Assistant
from qwen_agent.utils.output_beautify import typewriter_print

# ÂØºÂÖ•Â∑•ÂÖ∑Á±ª - ‰ΩøÁî®ÁªùÂØπÂØºÂÖ•
from src.tools.qwen_tools.memory_tools import get_memory_store

# ÂØºÂÖ•ÈÖçÁΩÆÁÆ°ÁêÜ
from src.config.settings import get_config, ConfigError
from src.config.mcp_config import get_mcp_config_loader
from src.config.prompt_manager import PromptManager, PromptManagerError

# ÂØºÂÖ•UIÂ∏ÆÂä©ÂáΩÊï∞
from src.ui import show_welcome, show_help, show_memory, clear_screen

# ÂÖ®Â±ÄPromptManagerÂÆû‰æã
prompt_manager = None


class APIConnectionError(Exception):
    """APIËøûÊé•ÈîôËØØ"""


class ModelConfigError(Exception):
    """Ê®°ÂûãÈÖçÁΩÆÈîôËØØ"""


class MCPConfigError(Exception):
    """MCPÈÖçÁΩÆÈîôËØØ"""


def initialize_prompt_manager():
    """ÂàùÂßãÂåñPromptManager - Â§±Ë¥•Êó∂Á´ãÂç≥ÊäõÂá∫ÂºÇÂ∏∏
    
    Returns:
        PromptManagerÂÆû‰æã
        
    Raises:
        PromptManagerError: ÊèêÁ§∫ËØçÈÖçÁΩÆÂä†ËΩΩÂ§±Ë¥•
    """
    global prompt_manager
    
    prompt_manager = PromptManager("config/prompts")
    print("‚úì ÊèêÁ§∫ËØçÈÖçÁΩÆÂä†ËΩΩÊàêÂäü")
    return prompt_manager


def get_prompt(prompt_key: str, variables: Dict[str, Any] = None) -> str:
    """Ëé∑ÂèñÊèêÁ§∫ËØçÔºåÈÖçÁΩÆÁº∫Â§±Êó∂Âø´ÈÄüÂ§±Ë¥•
    
    Args:
        prompt_key: ÊèêÁ§∫ËØçÈîÆ
        variables: ÂèòÈáèÊõøÊç¢Â≠óÂÖ∏
        
    Returns:
        ÊèêÁ§∫ËØçÂÜÖÂÆπ
        
    Raises:
        PromptManagerError: ÊèêÁ§∫ËØç‰∏çÂ≠òÂú®ÊàñÈÖçÁΩÆÈîôËØØÊó∂Á´ãÂç≥Â§±Ë¥•
    """
    global prompt_manager
    
    if not prompt_manager:
        raise PromptManagerError(f"PromptManagerÊú™ÂàùÂßãÂåñÔºÅÊó†Ê≥ïËé∑ÂèñÊèêÁ§∫ËØç: {prompt_key}")
    
    return prompt_manager.get_prompt(prompt_key, variables)


def setup_mcp_servers() -> Dict[str, Any]:
    """ËÆæÁΩÆMCPÊúçÂä°Âô®ÈÖçÁΩÆ - Â§±Ë¥•Êó∂Á´ãÂç≥ÊäõÂá∫ÂºÇÂ∏∏
    
    ‰ªéÈÖçÁΩÆÊñá‰ª∂Âä®ÊÄÅÂä†ËΩΩÂêØÁî®ÁöÑMCPÊúçÂä°Âô®
    
    Returns:
        MCPÊúçÂä°Âô®ÈÖçÁΩÆÂ≠óÂÖ∏ÔºåÁ¨¶ÂêàQwen-AgentÊ†ºÂºè
        
    Raises:
        MCPConfigError: MCPÈÖçÁΩÆÂä†ËΩΩÂ§±Ë¥•
    """
    # Ëé∑ÂèñMCPÈÖçÁΩÆÂä†ËΩΩÂô®
    config_loader = get_mcp_config_loader()
    
    # Ëé∑ÂèñÂêØÁî®ÁöÑÊúçÂä°Âô®
    enabled_servers = config_loader.get_enabled_servers()
    
    if not enabled_servers:
        raise MCPConfigError("‚ùå Êú™ÊâæÂà∞‰ªª‰ΩïÂêØÁî®ÁöÑMCPÊúçÂä°Âô®")
    
    # ÊûÑÂª∫Qwen-AgentÊ†ºÂºèÁöÑMCPÈÖçÁΩÆ
    mcp_servers = {}
    
    for server_name in enabled_servers:
        server_config = config_loader.get_server_config(server_name)
        if not server_config:
            raise MCPConfigError(f"‚ùå ÊúçÂä°Âô® '{server_name}' ÈÖçÁΩÆ‰∏çÂ≠òÂú®")
        
        # ËΩ¨Êç¢‰∏∫Qwen-AgentÊúüÊúõÁöÑÊ†ºÂºè
        qwen_config = {
            'command': server_config['command'],
            'args': server_config['args']
        }
        
        # Ê∑ªÂä†ÁéØÂ¢ÉÂèòÈáèÔºàÂ¶ÇÊûúÊúâÔºâ
        if 'env' in server_config:
            qwen_config['env'] = server_config['env']
        
        mcp_servers[server_name] = qwen_config
        
        # ÊòæÁ§∫Âä†ËΩΩÁöÑÊúçÂä°Âô®‰ø°ÊÅØ
        category = server_config.get('category', 'Êú™ÂàÜÁ±ª')
        print(f"‚úì Âä†ËΩΩMCPÊúçÂä°Âô®: {server_name} (ÂàÜÁ±ª: {category})")
    
    print(f"üì° ÊàêÂäüÂä†ËΩΩ {len(mcp_servers)} ‰∏™MCPÊúçÂä°Âô®")
    return mcp_servers


def create_llm_config() -> Dict:
    """ÂàõÂª∫LLMÈÖçÁΩÆ - Â§±Ë¥•Êó∂Á´ãÂç≥ÊäõÂá∫ÂºÇÂ∏∏"""
    
    config = get_config()
    
    # Ê£ÄÊü•ÊòØÂê¶Ë¶Å‰ΩøÁî®R1Êé®ÁêÜÊ®°Âûã
    use_r1 = config.get_bool('USE_DEEPSEEK_R1', False)
    
    # Ê£ÄÊü•DeepSeek APIÂØÜÈí• - Â§±Ë¥•Êó∂Á´ãÂç≥ÊäõÂá∫ÂºÇÂ∏∏
    api_key = config.require('DEEPSEEK_API_KEY')
    
    print("üîç Ê£ÄÊµãÂà∞DeepSeek APIÂØÜÈí•")
    
    base_url = 'https://api.deepseek.com/v1'
    
    if use_r1:
        model = 'deepseek-reasoner'  # R1-0528Êé®ÁêÜÊ®°Âûã
        model_name = "DeepSeek R1-0528 Êé®ÁêÜÊ®°Âûã"
    else:
        model = 'deepseek-chat'  # V3-0324 Á®≥ÂÆöÊ®°Âûã
        model_name = "DeepSeek V3 Á®≥ÂÆöÊ®°Âûã"
    
    # ‰∏çËøõË°åËøûÊé•ÊµãËØï - ‰ªª‰ΩïËøûÊé•ÈóÆÈ¢òÈÉΩÂú®ÂÆûÈôÖË∞ÉÁî®Êó∂Á´ãÂç≥Êö¥Èú≤
    print(f"‚ö° ‰ΩøÁî®{model_name}")
    
    return {
        'model': model,
        'model_server': base_url,
        'api_key': api_key,
        'generate_cfg': {
            'top_p': 0.8,
            'max_tokens': 2000,
            'temperature': 0.7
        }
    }


def create_tools_list() -> List[Any]:
    """ÂàõÂª∫Â∑•ÂÖ∑ÂàóË°® - Â§±Ë¥•Êó∂Á´ãÂç≥ÊäõÂá∫ÂºÇÂ∏∏
    
    Âä®ÊÄÅÊûÑÂª∫ÂåÖÂê´MCPÊúçÂä°Âô®ÁöÑÂ∑•ÂÖ∑ÂàóË°®
    
    Returns:
        Â∑•ÂÖ∑ÂàóË°®ÔºåÂåÖÂê´Ëá™ÂÆö‰πâÂ∑•ÂÖ∑ÂíåMCPÊúçÂä°Âô®ÈÖçÁΩÆ
        
    Raises:
        MCPConfigError: MCPÈÖçÁΩÆÂ§±Ë¥•
    """
    # ËÆæÁΩÆMCPÊúçÂä°Âô®
    mcp_servers = setup_mcp_servers()
    
    # ÊûÑÂª∫Â∑•ÂÖ∑ÂàóË°®
    tools = [
        'custom_save_info', 
        'custom_recall_info', 
        'custom_math_calc',
        {
            'mcpServers': mcp_servers  # ‰ΩøÁî®Âä®ÊÄÅÂä†ËΩΩÁöÑMCPÈÖçÁΩÆ
        },
        'code_interpreter',  # ÂÜÖÁΩÆ‰ª£Á†ÅËß£ÈáäÂô®Â∑•ÂÖ∑
    ]
    
    return tools


def main():
    """‰∏ªÂáΩÊï∞ - ‰∏ìÊ≥®‰∫éÁ®ãÂ∫èÊµÅÁ®ãÊéßÂà∂ÔºåÂ§±Ë¥•Êó∂Á´ãÂç≥Â¥©Ê∫É"""
    # 1. ÂàùÂßãÂåñÊèêÁ§∫ËØçÁÆ°ÁêÜÂô®
    initialize_prompt_manager()
    
    # 2. ÊòæÁ§∫Ê¨¢ËøéÁïåÈù¢
    show_welcome()
    
    # 3. ÂàõÂª∫Agent
    ai_loading_msg = get_prompt("ai_loading")
    print(f"\n{ai_loading_msg}")
    
    llm_cfg = create_llm_config()
    
    # 4. ËÆæÁΩÆMCPÊúçÂä°Âô®ÂíåÂ∑•ÂÖ∑
    mcp_loading_msg = get_prompt("mcp_loading")
    print(f"\n{mcp_loading_msg}")
    
    tools = create_tools_list()
    
    # Ëé∑ÂèñÁ≥ªÁªüÊèêÁ§∫ËØç - ‰ªéÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩ
    system_message = get_prompt("system_base")

    # ÂàõÂª∫Agent - ÂèÇËÄÉÂÆòÊñπQwen3Á§∫‰æã
    # Ëé∑ÂèñAgentÈÖçÁΩÆ
    agent_name = get_prompt("agent_name")
    agent_description = get_prompt("agent_description")
    
    agent = Assistant(
        llm=llm_cfg,
        system_message=system_message,
        function_list=tools,
        name=agent_name,
        description=agent_description
    )
    
    ai_success_msg = get_prompt("ai_success")
    print(ai_success_msg)
    
    # 5. ÂØπËØùÂæ™ÁéØ - ‰ªª‰ΩïÂºÇÂ∏∏ÈÉΩÁ´ãÂç≥Â¥©Ê∫É
    messages = []
    memory_store = get_memory_store()
    config = get_config()
    use_r1 = config.get_bool('USE_DEEPSEEK_R1', False)
    model_display = "DeepSeek-R1Êé®ÁêÜÊ®°Âûã" if use_r1 else "DeepSeek-V3Á®≥ÂÆöÊ®°Âûã"
    
    conversation_start_msg = get_prompt(
        "conversation_start",
        {"model_display": model_display}
    )
    print(f"\n{conversation_start_msg}\n")
    
    while True:
        # Ëé∑ÂèñÁî®Êà∑ËæìÂÖ• - Âè™Â§ÑÁêÜÁî®Êà∑‰∏≠Êñ≠
        user_input = input("ÊÇ®: ").strip()
        
        # Â§ÑÁêÜÁâπÊÆäÂëΩ‰ª§
        if user_input.lower() in ['quit', 'exit', 'q', 'ÈÄÄÂá∫']:
            goodbye_msg = get_prompt("goodbye_message")
            print(goodbye_msg)
            break
        elif user_input.lower() in ['help', 'h', 'Â∏ÆÂä©']:
            show_help()
            continue
        elif user_input.lower() in ['clear', 'cls', 'Ê∏ÖÂ±è']:
            clear_screen()
            continue
        elif user_input.lower() in ['memory', 'mem', 'ËÆ∞ÂøÜ']:
            show_memory()
            continue
        elif not user_input:
            continue
        
        # Ê∑ªÂä†Áî®Êà∑Ê∂àÊÅØÂà∞ÂéÜÂè≤
        messages.append({'role': 'user', 'content': user_input})
        
        # ÊòæÁ§∫AIÂõûÂ§ç
        ai_response_prefix = get_prompt("ai_response_prefix")
        print(f"\n{ai_response_prefix}", end='', flush=True)
        
        # Ë∞ÉÁî®AgentÂπ∂ÊµÅÂºèÊòæÁ§∫ - ‰ªª‰ΩïÂºÇÂ∏∏ÈÉΩÁ´ãÂç≥ÊäõÂá∫
        response_text = ""
        response_messages = agent.run(messages=messages)
        
        for response in response_messages:
            response_text = typewriter_print(response, response_text)
        
        # Ê∏ÖÁêÜÂπ∂Ê∑ªÂä†ÂìçÂ∫îÂà∞ÂéÜÂè≤ - ÁâπÂà´Â§ÑÁêÜR1Ê®°ÂûãÁöÑreasoning_content
        clean_messages = []
        for msg in response_messages:
            if isinstance(msg, dict):
                # ÂàõÂª∫Ê∏ÖÁêÜÂêéÁöÑÊ∂àÊÅØÂâØÊú¨ÔºåÁßªÈô§reasoning_content
                clean_msg = {k: v for k, v in msg.items() if k != 'reasoning_content'}
                clean_messages.append(clean_msg)
            else:
                clean_messages.append(msg)
        
        messages.extend(clean_messages)
        
        # ‰øùÂ≠òÂØπËØùÂà∞ÁÆÄÂçïÂéÜÂè≤ËÆ∞ÂΩï
        memory_store['history'].append({
            'user': user_input,
            'assistant': response_text,
            'timestamp': time.time()
        })
        
        # ‰øùÊåÅÂéÜÂè≤ËÆ∞ÂΩï‰∏çË∂ÖËøá50Êù°
        if len(memory_store['history']) > 50:
            memory_store['history'] = memory_store['history'][-50:]
        
        print()  # Êç¢Ë°å


if __name__ == "__main__":
    main() 